{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oX5avtpI5IRC"
      },
      "source": [
        "Importing required modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3JTyFz94s11"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential     # the model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint \n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNa2SChy5Ri3",
        "outputId": "8ff3753f-e418-4ed9-c736-df0c947082ac"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVeF6e1G7GtH"
      },
      "source": [
        "*Importing the dataframe*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzIHHLk55gsi"
      },
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IMDB/dataframe_train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "7Mqh3U5P5v7I",
        "outputId": "3252e383-4ab7-466d-d32e-1aa2c944fd62"
      },
      "source": [
        "#Visualizing the dataset\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>127_7.txt</td>\n",
              "      <td>Zentropa has much in common with The Third Man...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>126_10.txt</td>\n",
              "      <td>Zentropa is the most original movie I've seen ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>125_7.txt</td>\n",
              "      <td>Lars Von Trier is never backward in trying out...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>124_10.txt</td>\n",
              "      <td>*Contains spoilers due to me having to describ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123_10.txt</td>\n",
              "      <td>That was the first thing that sprang to mind a...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>12420_3.txt</td>\n",
              "      <td>There just isn't enough here. There a few funn...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>12419_1.txt</td>\n",
              "      <td>Tainted look at kibbutz life&lt;br /&gt;&lt;br /&gt;This f...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>12418_4.txt</td>\n",
              "      <td>I saw this movie, just now, not when it was re...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>12417_1.txt</td>\n",
              "      <td>Any film which begins with a cowhand shagging ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>12416_3.txt</td>\n",
              "      <td>Yes AWA wrestling how can anyone forget about ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              file                                             review label\n",
              "0        127_7.txt  Zentropa has much in common with The Third Man...   pos\n",
              "1       126_10.txt  Zentropa is the most original movie I've seen ...   pos\n",
              "2        125_7.txt  Lars Von Trier is never backward in trying out...   pos\n",
              "3       124_10.txt  *Contains spoilers due to me having to describ...   pos\n",
              "4       123_10.txt  That was the first thing that sprang to mind a...   pos\n",
              "...            ...                                                ...   ...\n",
              "24995  12420_3.txt  There just isn't enough here. There a few funn...   neg\n",
              "24996  12419_1.txt  Tainted look at kibbutz life<br /><br />This f...   neg\n",
              "24997  12418_4.txt  I saw this movie, just now, not when it was re...   neg\n",
              "24998  12417_1.txt  Any film which begins with a cowhand shagging ...   neg\n",
              "24999  12416_3.txt  Yes AWA wrestling how can anyone forget about ...   neg\n",
              "\n",
              "[25000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bAcqhZZ7oNn"
      },
      "source": [
        "Pre-processing on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe1rHoVe5wqo"
      },
      "source": [
        "for i in range(len(df)):\n",
        "  text=df['review'][i].lower()\n",
        "  text=text.replace(\"<br /><br />\",'')\n",
        "  clean_txt=''.join([c for c in text if c not in punctuation])\n",
        "  df['review'][i]=clean_txt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caXm0mij53zS"
      },
      "source": [
        "english_stops = set(stopwords.words('english'))\n",
        "x_data = df['review']\n",
        "list_rev = x_data.apply(lambda review: [w for w in review.split() if w not in english_stops])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV-YtHmF6Bgo"
      },
      "source": [
        "list_rev=np.asarray(list_rev)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa6GUkMq6C5h"
      },
      "source": [
        "#Encoding the labels\n",
        "for i in range(len(df)):\n",
        "  if df['label'][i]== 'pos':\n",
        "    df['label'][i]=1\n",
        "  elif df['label'][i]=='neg':\n",
        "    df['label'][i]=0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1sRmc_76G_q"
      },
      "source": [
        "encoded_labels=np.asarray(df['label']).astype('float32')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NR8UTYjp8LGZ"
      },
      "source": [
        "Splitting the Dataset into test(80%), train(10%) and validation(10%) set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhwlTG4k6M13"
      },
      "source": [
        "x_train, x_tes, y_train, y_tes = train_test_split(list_rev, encoded_labels, test_size = 0.2)\n",
        "x_test, x_valid, y_test, y_valid = train_test_split(x_tes, y_tes, test_size = 0.5)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ccG7-NZ6Q4m"
      },
      "source": [
        "#Function to get maximum length of dataset\n",
        "def get_max_length():\n",
        "    review_length = []\n",
        "    for review in x_train:\n",
        "        review_length.append(len(review))\n",
        "\n",
        "    return int(np.ceil(np.mean(review_length)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsgk8kIV6UZF",
        "outputId": "2d1206e7-b50d-4be7-f4a2-ae721b80b075"
      },
      "source": [
        "# ENCODING REVIEW by Padding the x_train,x_test and x_valid to fed into the LSTM\n",
        "token = Tokenizer(lower=False)  \n",
        "token.fit_on_texts(x_train)\n",
        "x_train = token.texts_to_sequences(x_train)\n",
        "x_test = token.texts_to_sequences(x_test)\n",
        "x_valid = token.texts_to_sequences(x_valid)\n",
        "\n",
        "max_length = get_max_length()\n",
        "\n",
        "x_train = pad_sequences(x_train, maxlen=max_length, padding='post', truncating='post')\n",
        "x_test = pad_sequences(x_test, maxlen=max_length, padding='post', truncating='post')\n",
        "x_valid = pad_sequences(x_valid, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "total_words = len(token.word_index) + 1   # add 1 because of 0 padding\n",
        "\n",
        "print('Encoded X Train\\n', x_train, '\\n')\n",
        "print('Encoded X Test\\n', x_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded X Train\n",
            " [[ 1688  3367     1 ...    41    55   415]\n",
            " [    1 51089    83 ...     0     0     0]\n",
            " [  311     8   101 ...     0     0     0]\n",
            " ...\n",
            " [  422   155  1599 ...     0     0     0]\n",
            " [  110    30    24 ...     5    10   151]\n",
            " [  101   211  4802 ...     0     0     0]] \n",
            "\n",
            "Encoded X Test\n",
            " [[  1537   2667 110658 ...  26628    833      9]\n",
            " [  6132      1   1086 ...   7246    712   8867]\n",
            " [ 77895  13258  16039 ...      0      0      0]\n",
            " ...\n",
            " [    47     19    177 ...      0      0      0]\n",
            " [     3    403     24 ...      0      0      0]\n",
            " [   329   3819     69 ...      0      0      0]] \n",
            "\n",
            "Maximum review length:  122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgzYDbzU98DH"
      },
      "source": [
        "Creating Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MkwGSux6ZPR",
        "outputId": "facf6ef6-f128-49ca-ec9a-0339e825c4ac"
      },
      "source": [
        "# ARCHITECTURE\n",
        "EMBED_DIM = 32\n",
        "LSTM_OUT = 64\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, EMBED_DIM, input_length = max_length))\n",
        "model.add(LSTM(LSTM_OUT))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 122, 32)           3981248   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,006,145\n",
            "Trainable params: 4,006,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J70Ck346d2Z"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\n",
        "    'models/LSTM.h5',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5CV_MbT6jXT",
        "outputId": "880cb0fb-bd30-4403-e270-6107e3a3ab25"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size = 128, epochs = 5,validation_data=(x_test,y_test), callbacks=[checkpoint])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 37s 216ms/step - loss: 0.6795 - accuracy: 0.5469 - val_loss: 0.5123 - val_accuracy: 0.8032\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.54685, saving model to models/LSTM.h5\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 33s 210ms/step - loss: 0.3408 - accuracy: 0.8628 - val_loss: 0.3192 - val_accuracy: 0.8676\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.54685 to 0.86280, saving model to models/LSTM.h5\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 32s 202ms/step - loss: 0.1331 - accuracy: 0.9577 - val_loss: 0.3453 - val_accuracy: 0.8700\n",
            "\n",
            "Epoch 00003: accuracy improved from 0.86280 to 0.95770, saving model to models/LSTM.h5\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 32s 205ms/step - loss: 0.0587 - accuracy: 0.9856 - val_loss: 0.4094 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.95770 to 0.98560, saving model to models/LSTM.h5\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 32s 205ms/step - loss: 0.0321 - accuracy: 0.9941 - val_loss: 0.6492 - val_accuracy: 0.8508\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.98560 to 0.99410, saving model to models/LSTM.h5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efd291e2910>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKwXtDNP-UO7"
      },
      "source": [
        "**Getting prediction on validation Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePKrJdqA6nam",
        "outputId": "58a12dc4-13db-4220-b8dd-b336e2c78690"
      },
      "source": [
        "y_pred1 = model.predict(x_valid, batch_size = 128)\n",
        "y_pred=[int(num>0.5) for num in y_pred1]\n",
        "true = 0\n",
        "for i, y in enumerate(y_valid):\n",
        "    if y == y_pred[i]:\n",
        "        true += 1\n",
        "\n",
        "print('Correct Prediction: {}'.format(true))\n",
        "print('Wrong Prediction: {}'.format(len(y_pred) - true))\n",
        "print('Accuracy: {}'.format(true/len(y_pred)*100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Prediction: 2152\n",
            "Wrong Prediction: 348\n",
            "Accuracy: 86.08\n"
          ]
        }
      ]
    }
  ]
}